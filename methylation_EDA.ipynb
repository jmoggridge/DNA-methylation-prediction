{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "improved-product",
   "metadata": {},
   "source": [
    "\n",
    "# Data cleaning and feature engineering\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "convertible-breakdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-fifteen",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Load data and rename columns\n",
    "\n",
    "#### Training data:\n",
    "\n",
    "- 29k rows x 10 cols, \n",
    "- 'Beta' is outcome: methylated or not \n",
    "- Chromosomes 1-10\n",
    "\n",
    "#### Test: \n",
    "- 20,611 rows, no outcome labels\n",
    "- Chromosomes 11-22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "elect-villa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29065 entries, 0 to 29064\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype   \n",
      "---  ------         --------------  -----   \n",
      " 0   position       29065 non-null  float64 \n",
      " 1   island         23717 non-null  object  \n",
      " 2   refgene        24822 non-null  string  \n",
      " 3   rel_to_island  23717 non-null  category\n",
      " 4   feature        16421 non-null  object  \n",
      " 5   fwd_seq        29065 non-null  string  \n",
      " 6   seq            29065 non-null  string  \n",
      "dtypes: category(1), float64(1), object(2), string(3)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "\n",
    "# give the data names that don't suck\n",
    "train = train.rename(columns={\"Id\": \"id\",\n",
    "                              \"CHR\": \"chromosome\", \n",
    "                              \"MAPINFO\": \"position\",\n",
    "                              \"UCSC_CpG_Islands_Name\": \"island\",  \n",
    "                              \"UCSC_RefGene_Group\":\"refgene\",\n",
    "                              \"Relation_to_UCSC_CpG_Island\": \"rel_to_island\",\n",
    "                              \"Regulatory_Feature_Group\": \"feature\",\n",
    "                              \"Forward_Sequence\":\"fwd_seq\",\n",
    "                              \"Beta\": \"outcome\"})\n",
    "\n",
    "# change categorical variables dtypes\n",
    "for col in [\"rel_to_island\", \"outcome\"]:\n",
    "    train[col] = train[col].astype(\"category\")\n",
    "for col in [\"fwd_seq\", \"seq\", \"refgene\"]:\n",
    "    train[col] = train[col].astype(\"string\")\n",
    "train['position'] = train['position'].astype('float64')\n",
    "del(col)\n",
    "\n",
    "Y = train['outcome']\n",
    "df = train.drop(['id', 'chromosome', 'outcome'], 1)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "abstract-classroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.iloc[:100, ]\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-ground",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "## Features of the data \n",
    "\n",
    "- `id`: unique identifiers \n",
    "  - not useful for training, useful for data handling though  \n",
    "  \n",
    "  \n",
    "- `chromosome, position` (exact CpG site): \n",
    "  - not really sure how to use this given that test is from different chromosomes  \n",
    "  - don't want classifier to memorize positions (values = n)  \n",
    "  - could derive other features like size of island, placement of cg inside of island  \n",
    "    \n",
    "    \n",
    "- `island`: chr + position range of island  \n",
    "  - again, very specific to each site which could lead to over training  \n",
    "  - some missing data (4k)  \n",
    "  \n",
    "- `refgene`: UCSC_RefGene_Group\n",
    "  - 1089 unique values...\n",
    "  - contains list of tags about functional elements:\n",
    "      - TSS* {200, .}\n",
    "      - 1st exon\n",
    "      - Body\n",
    "      - 5'UTR\n",
    "  - Each can have multiple tags, even multiple of same tags....\n",
    "  - Maybe split into counts for each tag: columns [TSS200, TSS1500, exon1, body, utr5, ...]\n",
    "\n",
    "Body:14797  TSS200:10935   5'UTR:9117 1stExon:6928 TSS1500:7634   3'UTR:866    NA's:4243 \n",
    "                           \n",
    "\n",
    "- `feature`: lots of missing data, seems like 2 different factors\n",
    "  - Promoter/Gene/NonGene_Associated or Unclassified  \n",
    "      - not Cell_type_specific\n",
    "  - Promoter/Gene/NonGene_Associated_Cell_type_specific or Unclassified_Cell_type_specific\n",
    "  - NA (~12k)\n",
    "  \n",
    "  \n",
    "- `relation_to_island`:\n",
    "  - 5 levels: Island:18269, S_Shore:2107, N_Shelf: 529, N_Shore: 2378, S_Shelf: 434, NA's: 5348\n",
    "  \n",
    "  \n",
    "- `Fwd_seq` and `seq`:\n",
    "  - not sure what is the relationship between these?\n",
    "  - `Fwd_seq` has the [CG] site marked and are all 124 bp long\n",
    "  - `seq` is 2kbp of sequence\n",
    "\n",
    "  \n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-meeting",
   "metadata": {},
   "source": [
    "## Nominal data\n",
    "  \n",
    "  <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ahead-proposal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<StringArray>\n",
      "[                                'Body;Body',\n",
      "                                    'TSS200',\n",
      "                               \"5'UTR;5'UTR\",\n",
      "                                      'Body',\n",
      "                           '1stExon;1stExon',\n",
      "                        \"5'UTR;TSS200;5'UTR\",\n",
      "                                        <NA>,\n",
      "                       'Body;Body;Body;Body',\n",
      " \"5'UTR;1stExon;1stExon;5'UTR;1stExon;5'UTR\",\n",
      "                           'TSS1500;TSS1500']\n",
      "Length: 10, dtype: string\n"
     ]
    }
   ],
   "source": [
    "# refgene has lists of tags\n",
    "print(df['refgene'].unique()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "billion-trust",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan 'Promoter_Associated' 'Unclassified' 'Gene_Associated'\n",
      " 'Unclassified_Cell_type_specific'\n",
      " 'Promoter_Associated_Cell_type_specific' 'NonGene_Associated'\n",
      " 'Gene_Associated_Cell_type_specific'\n",
      " 'NonGene_Associated_Cell_type_specific']\n"
     ]
    }
   ],
   "source": [
    "# feature has 2 categories: classes (celltype_specific or not)\n",
    "# and (promoter / gene / non-gene / unclassified)\n",
    "print(df['feature'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "constitutional-origin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Island', nan, 'S_Shore', 'N_Shelf', 'N_Shore', 'S_Shelf'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# relation to island is one of 5 levels or unknown\n",
    "print(list(df['rel_to_island'].unique()), '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-serum",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Making dummy variables for categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "significant-plymouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dummies(df):\n",
    "    \"\"\"Make various dummies for (relation to island), (refgene group), (regulatory features)\"\"\"\n",
    "    \n",
    "    dfx = df.copy()\n",
    "    ## get dummies for \"Relation_to_UCSC_CpG_Island\": 5 levels\n",
    "    dfx = pd.get_dummies(dfx, columns =['rel_to_island'], prefix_sep = '', prefix = '')\n",
    "    \n",
    "    ## pull terms from 'UCSC_RefGene_Group' lists into columns of counts\n",
    "    for term in [\"TSS200\", \"TSS1500\", \"Body\", \"5'UTR\", \"3'UTR\", \"1stExon\"]:\n",
    "        dfx[term] = dfx[\"refgene\"].str.count(term)\n",
    "        dfx[term] = dfx[term].fillna(0).astype('int32')\n",
    "\n",
    "    ## create 2 sets of dummies from 'feature' (Regulatory_Feature_Group)\n",
    "    df[\"cell_type_specific\"] = df['feature'].str.count(\"_Cell_type_specific\").fillna(0).astype('int32')\n",
    "    for term in [\"Gene_Associated\", \"NonGene_Associated\", \"Promoter_Associated\", \"Unclassified\"]:\n",
    "        dfx[term] = dfx['feature'].str.count(term).fillna(0).astype('int32')\n",
    "\n",
    "    dfx = dfx.drop(columns = ['position', 'island', 'refgene', 'feature', 'fwd_seq', 'seq'])\n",
    "    return(dfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "mechanical-texas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_type_specific</th>\n",
       "      <th>Island</th>\n",
       "      <th>N_Shelf</th>\n",
       "      <th>N_Shore</th>\n",
       "      <th>S_Shelf</th>\n",
       "      <th>S_Shore</th>\n",
       "      <th>TSS200</th>\n",
       "      <th>TSS1500</th>\n",
       "      <th>Body</th>\n",
       "      <th>5'UTR</th>\n",
       "      <th>3'UTR</th>\n",
       "      <th>1stExon</th>\n",
       "      <th>Gene_Associated</th>\n",
       "      <th>NonGene_Associated</th>\n",
       "      <th>Promoter_Associated</th>\n",
       "      <th>Unclassified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>29065.000000</td>\n",
       "      <td>29065.000000</td>\n",
       "      <td>29065.000000</td>\n",
       "      <td>29065.000000</td>\n",
       "      <td>29065.000000</td>\n",
       "      <td>29065.000000</td>\n",
       "      <td>29065.000000</td>\n",
       "      <td>29065.000000</td>\n",
       "      <td>29065.000000</td>\n",
       "      <td>29065.000000</td>\n",
       "      <td>29065.000000</td>\n",
       "      <td>29065.000000</td>\n",
       "      <td>29065.000000</td>\n",
       "      <td>29065.000000</td>\n",
       "      <td>29065.000000</td>\n",
       "      <td>29065.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.079615</td>\n",
       "      <td>0.628557</td>\n",
       "      <td>0.018201</td>\n",
       "      <td>0.081817</td>\n",
       "      <td>0.014932</td>\n",
       "      <td>0.072493</td>\n",
       "      <td>0.376226</td>\n",
       "      <td>0.262653</td>\n",
       "      <td>0.509100</td>\n",
       "      <td>0.313676</td>\n",
       "      <td>0.029795</td>\n",
       "      <td>0.238362</td>\n",
       "      <td>0.010769</td>\n",
       "      <td>0.006744</td>\n",
       "      <td>0.421607</td>\n",
       "      <td>0.132599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.270700</td>\n",
       "      <td>0.483199</td>\n",
       "      <td>0.133678</td>\n",
       "      <td>0.274090</td>\n",
       "      <td>0.121283</td>\n",
       "      <td>0.259306</td>\n",
       "      <td>0.822772</td>\n",
       "      <td>0.693371</td>\n",
       "      <td>1.024202</td>\n",
       "      <td>0.777718</td>\n",
       "      <td>0.309063</td>\n",
       "      <td>0.642950</td>\n",
       "      <td>0.103215</td>\n",
       "      <td>0.081843</td>\n",
       "      <td>0.493825</td>\n",
       "      <td>0.339147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cell_type_specific        Island       N_Shelf       N_Shore  \\\n",
       "count        29065.000000  29065.000000  29065.000000  29065.000000   \n",
       "mean             0.079615      0.628557      0.018201      0.081817   \n",
       "std              0.270700      0.483199      0.133678      0.274090   \n",
       "min              0.000000      0.000000      0.000000      0.000000   \n",
       "25%              0.000000      0.000000      0.000000      0.000000   \n",
       "50%              0.000000      1.000000      0.000000      0.000000   \n",
       "75%              0.000000      1.000000      0.000000      0.000000   \n",
       "max              1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "            S_Shelf       S_Shore        TSS200       TSS1500          Body  \\\n",
       "count  29065.000000  29065.000000  29065.000000  29065.000000  29065.000000   \n",
       "mean       0.014932      0.072493      0.376226      0.262653      0.509100   \n",
       "std        0.121283      0.259306      0.822772      0.693371      1.024202   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      1.000000      0.000000      1.000000   \n",
       "max        1.000000      1.000000     23.000000      9.000000     22.000000   \n",
       "\n",
       "              5'UTR         3'UTR       1stExon  Gene_Associated  \\\n",
       "count  29065.000000  29065.000000  29065.000000     29065.000000   \n",
       "mean       0.313676      0.029795      0.238362         0.010769   \n",
       "std        0.777718      0.309063      0.642950         0.103215   \n",
       "min        0.000000      0.000000      0.000000         0.000000   \n",
       "25%        0.000000      0.000000      0.000000         0.000000   \n",
       "50%        0.000000      0.000000      0.000000         0.000000   \n",
       "75%        0.000000      0.000000      0.000000         0.000000   \n",
       "max       20.000000     24.000000     20.000000         1.000000   \n",
       "\n",
       "       NonGene_Associated  Promoter_Associated  Unclassified  \n",
       "count        29065.000000         29065.000000  29065.000000  \n",
       "mean             0.006744             0.421607      0.132599  \n",
       "std              0.081843             0.493825      0.339147  \n",
       "min              0.000000             0.000000      0.000000  \n",
       "25%              0.000000             0.000000      0.000000  \n",
       "50%              0.000000             0.000000      0.000000  \n",
       "75%              0.000000             1.000000      0.000000  \n",
       "max              1.000000             1.000000      1.000000  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies = make_dummies(df)\n",
    "dummies.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-sunday",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Position relative to nearby CpG Island\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "involved-vacuum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_relative_positions(df):\n",
    "    \"\"\" island col has position info like: \"chr1:2004858-2005346\"\n",
    "        We want to get the position of the CpG site relative to the start and stop of the island\n",
    "        Many columns don't have island data so add a dummy to indicate whether it exists\n",
    "    \"\"\"\n",
    "    dfx = df.copy()\n",
    "    # dummy variable for whether has 'island' or NA\n",
    "    dfx['has_island'] = np.where(dfx['island'].isna(), 0, 1)\n",
    "    \n",
    "    # postion of CpG relative to nearby island start position (lots of missing values though)\n",
    "    dfx['isl_start'] = dfx['island'].str.extract(':(\\d+)').astype('float64')\n",
    "    dfx['dist_start'] = dfx['isl_start'] - dfx['position']\n",
    "    dfx['dist_start'] = dfx['dist_start'].fillna(0)\n",
    "    \n",
    "    # same for distance to end of island\n",
    "    dfx['isl_end'] = dfx['island'].str.extract('-(\\d+)').astype('float64')\n",
    "    dfx['dist_end'] = dfx['isl_end'] - df['position']\n",
    "    dfx['dist_end'] = dfx['dist_end'].fillna(0)\n",
    "    \n",
    "    # return distance columns\n",
    "    return(dfx[['has_island', 'dist_start', 'dist_end']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "numerical-restoration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_island</th>\n",
       "      <th>dist_start</th>\n",
       "      <th>dist_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>29065.000000</td>\n",
       "      <td>29065.000000</td>\n",
       "      <td>29065.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.815999</td>\n",
       "      <td>-386.790986</td>\n",
       "      <td>416.893136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.387492</td>\n",
       "      <td>930.098933</td>\n",
       "      <td>942.305462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-13788.000000</td>\n",
       "      <td>-3997.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-626.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-229.000000</td>\n",
       "      <td>240.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>646.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>14685.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         has_island    dist_start      dist_end\n",
       "count  29065.000000  29065.000000  29065.000000\n",
       "mean       0.815999   -386.790986    416.893136\n",
       "std        0.387492    930.098933    942.305462\n",
       "min        0.000000 -13788.000000  -3997.000000\n",
       "25%        1.000000   -626.000000      0.000000\n",
       "50%        1.000000   -229.000000    240.000000\n",
       "75%        1.000000      0.000000    646.000000\n",
       "max        1.000000   3999.000000  14685.000000"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = make_relative_positions(df)\n",
    "pos.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-convert",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Encoding sequences\n",
    "\n",
    "There are shorter regions (60 bp up and downstream) and longer sequences (2kbp)\n",
    "\n",
    "The shorter sequence always has 60 bp, then \"[CG]\", then 60 bp downstream.\n",
    "```\n",
    "print(df['short_l'][1])\n",
    "print(set(len(x) for x in df['short_l']), set(len(x) for x in df['short_r']))\n",
    "> GGACCACACTGCCATGGCAACAGCGTGCCTCTGCGTCCTCCATCCGGGCCTCTCTAACTA\n",
    "> {60} {60}\n",
    "\n",
    "```\n",
    "\n",
    "The longer sequence contains the shorter in the center, always starting in the same position (939; from 0-index).\n",
    "```\n",
    "for x in range(10):\n",
    "    pos = df['seq'][x].find(re.sub(r'[\\[|\\]]', '', df['fwd_seq'][x]))\n",
    "    print(pos)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "regional-playback",
   "metadata": {},
   "outputs": [],
   "source": [
    "## with help from: https://www.kaggle.com/thomasnelson/working-with-dna-sequence-data-for-ml\n",
    "\n",
    "def make_kmer_freq(df):\n",
    "    \"\"\"returns vectorized kmer frequency features as dataframe\"\"\"\n",
    "    \n",
    "    def get_kmers(dna, k=6):\n",
    "        \"\"\"creates list of kmers from dna seq\"\"\"\n",
    "        dna = dna.upper()\n",
    "        kmers = [dna[x:x+k] for x in range(len(dna)+1-k)]\n",
    "        kmers = ' '.join(kmers)\n",
    "        return(kmers)\n",
    "    \n",
    "    # create new column of \n",
    "    mers = df.apply(lambda x: get_kmers(x['seq'], 6), axis = 1)\n",
    "    tfidf = TfidfVectorizer() \n",
    "    X = tfidf.fit_transform(mers)\n",
    "    kmers = tfidf.get_feature_names()\n",
    "    kmer_df = pd.DataFrame(X.toarray(), columns=kmers)\n",
    "    return(kmer_df)\n",
    "\n",
    "\n",
    "def make_one_hot_seq(df):\n",
    "    \n",
    "    def one_hot_encode_dna(dna):\n",
    "        \"\"\" One-hot encode a single DNA sequence: \n",
    "        Requires creating two encoders: LabelEncoder to get from string to numeric, then OneHotEncoder\n",
    "        Converts DNA to numeric then to one-hot matrix with shape: len(dna)*4\n",
    "        \"\"\"\n",
    "        # create label encoder for DNA symbols\n",
    "        label_encoder = LabelEncoder() \n",
    "        label_encoder.fit(np.array(list('ACGTN')))\n",
    "\n",
    "        # create one-hot encoder\n",
    "        onehot_encoder = OneHotEncoder(sparse=False, dtype=int)\n",
    "\n",
    "        # dna to numeric array\n",
    "        dna = re.sub('[^ACGT]', 'N', dna.upper())\n",
    "        dna = np.array(list(dna))\n",
    "        dna_int = label_encoder.transform(dna) \n",
    "        dna_int = dna_int.reshape(len(dna_int), 1)\n",
    "\n",
    "        # convert to one-hot\n",
    "        dna_onehot = onehot_encoder.fit_transform(dna_int)\n",
    "        return(dna_onehot)\n",
    "    \n",
    "    \"\"\"\n",
    "    Splits the region around CpG site in up + downstream\n",
    "    Applies one-hot encoding to each sequence and returns 480 column df\n",
    "    \"\"\"\n",
    "    dfx = df.copy()\n",
    "    # split the upstream and downstream seq around '[CpG]'; rejoin the two halves\n",
    "    dfx['fwd_seq_x'] = dfx['fwd_seq'].str.split('\\[|\\]', expand = True).apply(lambda x: x[0] + x[2], axis=1)\n",
    "\n",
    "    # apply one_hot_encoding to sequence and flatten matrix into vector\n",
    "    X1 = dfx.apply(lambda x: one_hot_encode_dna(x['fwd_seq_x']).flatten(), axis=1)\n",
    "    \n",
    "    # stack vectors into data frame with 480 columns (x1 to x480), since [120 bp * 4 bases] are encoded.\n",
    "    X1 = pd.DataFrame(np.column_stack(list(zip(*X1))), \n",
    "                      columns = list(x+str(y) for y in range(120) for x in 'ACGT'))\n",
    "\n",
    "    return(X1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "answering-ranking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29065 entries, 0 to 29064\n",
      "Columns: 4104 entries, aaaaaa to tttttt\n",
      "dtypes: float64(4104)\n",
      "memory usage: 910.1 MB\n"
     ]
    }
   ],
   "source": [
    "kmer_freq = make_kmer_freq(df)\n",
    "kmer_freq.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "racial-factor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29065 entries, 0 to 29064\n",
      "Columns: 480 entries, A0 to T119\n",
      "dtypes: int64(480)\n",
      "memory usage: 106.4 MB\n"
     ]
    }
   ],
   "source": [
    "one_hot_df = make_one_hot_seq(df)\n",
    "one_hot_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-tracy",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Combine all the features together for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "sudden-anchor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_all_features(df):\n",
    "    return(pd.concat([make_relative_positions(df.copy()),\n",
    "                      make_dummies(df.copy()), \n",
    "                      make_kmer_freq(df.copy()), \n",
    "                      make_one_hot_seq(df.copy())], \n",
    "                     1)\n",
    "          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-happening",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = make_all_features(df)\n",
    "X.to_csv(\"data/train_X.csv\")\n",
    "Y.to_csv(\"data/train_Y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-nature",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "coral-judge",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-rochester",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-methodology",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-letter",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-buying",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "\n",
    "# Test data\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-dress",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Same thing for test data\n",
    "test = pd.read_csv('data/test.csv')\n",
    "test = test.rename(columns={\"Id\": \"id\",\n",
    "                              \"CHR\": \"chromosome\", \n",
    "                              \"MAPINFO\": \"position\",\n",
    "                              \"UCSC_CpG_Islands_Name\": \"island\",  \n",
    "                              \"UCSC_RefGene_Group\":\"refgene\",\n",
    "                              \"Relation_to_UCSC_CpG_Island\": \"rel_to_island\",\n",
    "                              \"Regulatory_Feature_Group\": \"feature\",\n",
    "                              \"Forward_Sequence\":\"fwd_seq\"})\n",
    "\n",
    "# change categorical variables dtypes\n",
    "test[\"rel_to_island\"] = test[\"rel_to_island\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-england",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-compound",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
